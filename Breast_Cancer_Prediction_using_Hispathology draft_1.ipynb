{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d_BOL5f9Dl5t"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import tarfile\n",
        "import os\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DQo2wSoDqSn",
        "outputId": "af634b31-921b-43fb-cfc3-ff083aaa622c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HuqpPPdCDrpV"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset archive on Google Drive\n",
        "archive_path = '/content/drive/MyDrive/BreaKHis_v1.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cwfbIvf1DyuP"
      },
      "outputs": [],
      "source": [
        "# Directory where the dataset will be extracted\n",
        "extract_dir = '/content/BreaKHis_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fqkYg4ZmDt9f"
      },
      "outputs": [],
      "source": [
        "# Create a directory if it does not exist\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKFWVKPjD3JR",
        "outputId": "01d6ae86-49cf-4302-98d1-73a5efe0b395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction completed!\n"
          ]
        }
      ],
      "source": [
        "# Extract the dataset\n",
        "with tarfile.open(archive_path, 'r:gz') as archive:\n",
        "    archive.extractall(path=extract_dir)\n",
        "\n",
        "print('Extraction completed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f2FDypJCD4o1"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset directory\n",
        "base_dir = '/content/BreaKHis_dataset/BreaKHis_v1/histology_slides/breast'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkoOcXB9EW-w",
        "outputId": "236576a3-e95a-425d-aaf5-55d470b42e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6328 images belonging to 2 classes.\n",
            "Found 1581 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Prepare data generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # using 20% of the data for validation\n",
        ")\n",
        "\n",
        "train_it = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='binary',  # or 'categorical' if multi-class\n",
        "    batch_size=32,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_it = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='binary',  # or 'categorical' if multi-class\n",
        "    batch_size=32,\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69WQXpc_Ebos",
        "outputId": "5f5a53f5-e6e9-4069-d6a0-4fca8f585a2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# CNN Model\n",
        "def build_cnn_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # or 'softmax' for multi-class\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EzKguXntEliT"
      },
      "outputs": [],
      "source": [
        "# Train models\n",
        "def train_model(model, train_it, val_it):\n",
        "    history = model.fit(\n",
        "        train_it,\n",
        "        steps_per_epoch=train_it.samples // train_it.batch_size,\n",
        "        validation_data=val_it,\n",
        "        validation_steps=val_it.samples // val_it.batch_size,\n",
        "        epochs=5\n",
        "    )\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VSXllW7EoIJ",
        "outputId": "691e9bd1-eb7b-4f41-9076-dc74f7b9ed0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 512ms/step - accuracy: 0.7299 - loss: 0.7937 - val_accuracy: 0.7997 - val_loss: 0.4623\n",
            "Epoch 2/5\n",
            "\u001b[1m  1/197\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8438 - loss: 0.4779"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4779 - val_accuracy: 0.7692 - val_loss: 0.4776\n",
            "Epoch 3/5\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 474ms/step - accuracy: 0.7991 - loss: 0.4798 - val_accuracy: 0.7915 - val_loss: 0.4645\n",
            "Epoch 4/5\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8438 - loss: 0.4345 - val_accuracy: 0.7692 - val_loss: 0.3983\n",
            "Epoch 5/5\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 474ms/step - accuracy: 0.8151 - loss: 0.4459 - val_accuracy: 0.8335 - val_loss: 0.3866\n"
          ]
        }
      ],
      "source": [
        "cnn_history = train_model(cnn_model, train_it, val_it)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
